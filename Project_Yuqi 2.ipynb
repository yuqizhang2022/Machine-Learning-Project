{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28101ad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T19:47:49.205985Z",
     "start_time": "2022-05-05T19:47:44.362725Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33808c99",
   "metadata": {},
   "source": [
    "### prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa9406b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T23:39:16.639874Z",
     "start_time": "2022-04-07T23:39:15.063522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Value</th>\n",
       "      <th>S</th>\n",
       "      <th>K</th>\n",
       "      <th>tau</th>\n",
       "      <th>r</th>\n",
       "      <th>BS</th>\n",
       "      <th>BS_binary</th>\n",
       "      <th>KS_ratio</th>\n",
       "      <th>KS_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>KS_tau_ratio</th>\n",
       "      <th>r_asset</th>\n",
       "      <th>risk_free_rate_abs</th>\n",
       "      <th>risk_free_rate_prop</th>\n",
       "      <th>S_expected</th>\n",
       "      <th>S_bin</th>\n",
       "      <th>K_bin</th>\n",
       "      <th>r_bin</th>\n",
       "      <th>is_low_K</th>\n",
       "      <th>is_high_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>431.618600</td>\n",
       "      <td>460</td>\n",
       "      <td>0.293651</td>\n",
       "      <td>0.03147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.065756</td>\n",
       "      <td>28.381400</td>\n",
       "      <td>...</td>\n",
       "      <td>3.629330</td>\n",
       "      <td>0.242183</td>\n",
       "      <td>0.210713</td>\n",
       "      <td>0.870057</td>\n",
       "      <td>455.833554</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.633296</td>\n",
       "      <td>420</td>\n",
       "      <td>0.182540</td>\n",
       "      <td>0.03147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.970799</td>\n",
       "      <td>-12.633296</td>\n",
       "      <td>...</td>\n",
       "      <td>5.318291</td>\n",
       "      <td>-0.149858</td>\n",
       "      <td>-0.181328</td>\n",
       "      <td>1.209998</td>\n",
       "      <td>417.631191</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.633296</td>\n",
       "      <td>430</td>\n",
       "      <td>0.182540</td>\n",
       "      <td>0.03147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>-2.633296</td>\n",
       "      <td>...</td>\n",
       "      <td>5.444916</td>\n",
       "      <td>-0.032893</td>\n",
       "      <td>-0.064363</td>\n",
       "      <td>1.956735</td>\n",
       "      <td>427.574791</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>431.618600</td>\n",
       "      <td>415</td>\n",
       "      <td>0.293651</td>\n",
       "      <td>0.03147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961497</td>\n",
       "      <td>-16.618600</td>\n",
       "      <td>...</td>\n",
       "      <td>3.274287</td>\n",
       "      <td>-0.125156</td>\n",
       "      <td>-0.156626</td>\n",
       "      <td>1.251447</td>\n",
       "      <td>411.241141</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>434.772855</td>\n",
       "      <td>420</td>\n",
       "      <td>0.043651</td>\n",
       "      <td>0.03147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.966022</td>\n",
       "      <td>-14.772855</td>\n",
       "      <td>...</td>\n",
       "      <td>22.130678</td>\n",
       "      <td>-0.547037</td>\n",
       "      <td>-0.578507</td>\n",
       "      <td>1.057528</td>\n",
       "      <td>419.432326</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Value           S    K       tau        r  BS  BS_binary  \\\n",
       "0        1675    NaN  431.618600  460  0.293651  0.03147 NaN        NaN   \n",
       "1        1676    NaN  432.633296  420  0.182540  0.03147 NaN        NaN   \n",
       "2        1677    NaN  432.633296  430  0.182540  0.03147 NaN        NaN   \n",
       "3        1678    NaN  431.618600  415  0.293651  0.03147 NaN        NaN   \n",
       "4        1679    NaN  434.772855  420  0.043651  0.03147 NaN        NaN   \n",
       "\n",
       "   KS_ratio    KS_diff  ...  KS_tau_ratio   r_asset  risk_free_rate_abs  \\\n",
       "0  1.065756  28.381400  ...      3.629330  0.242183            0.210713   \n",
       "1  0.970799 -12.633296  ...      5.318291 -0.149858           -0.181328   \n",
       "2  0.993913  -2.633296  ...      5.444916 -0.032893           -0.064363   \n",
       "3  0.961497 -16.618600  ...      3.274287 -0.125156           -0.156626   \n",
       "4  0.966022 -14.772855  ...     22.130678 -0.547037           -0.578507   \n",
       "\n",
       "   risk_free_rate_prop  S_expected  S_bin  K_bin  r_bin  is_low_K  is_high_r  \n",
       "0             0.870057  455.833554      1      4      5         0          1  \n",
       "1             1.209998  417.631191      1      2      5         0          1  \n",
       "2             1.956735  427.574791      1      2      5         0          1  \n",
       "3             1.251447  411.241141      1      1      5         0          1  \n",
       "4             1.057528  419.432326      2      2      5         0          1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_excel('option_test_feature_added.xlsx')\n",
    "train=pd.read_excel('option_train_feature_added.xlsx')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4804c24e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T23:37:02.230119Z",
     "start_time": "2022-04-07T23:37:02.214131Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train=train.loc[:,rankedvariable]\n",
    "# X_test=test.loc[:,rankedvariable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044e9528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T08:04:50.531248Z",
     "start_time": "2022-05-05T08:04:50.498407Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test=train_test_split(train,test_size=0.3,random_state=2,stratify=train['BS_binary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079d7e8",
   "metadata": {},
   "source": [
    "### start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7a0075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T19:47:53.280934Z",
     "start_time": "2022-05-05T19:47:53.204371Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>S</th>\n",
       "      <th>K</th>\n",
       "      <th>tau</th>\n",
       "      <th>r</th>\n",
       "      <th>BS</th>\n",
       "      <th>BS_binary</th>\n",
       "      <th>KS_ratio</th>\n",
       "      <th>KS_diff</th>\n",
       "      <th>risk_free_FV</th>\n",
       "      <th>...</th>\n",
       "      <th>KS_tau_ratio</th>\n",
       "      <th>r_asset</th>\n",
       "      <th>risk_free_rate_abs</th>\n",
       "      <th>risk_free_rate_prop</th>\n",
       "      <th>S_expected</th>\n",
       "      <th>S_bin</th>\n",
       "      <th>K_bin</th>\n",
       "      <th>r_bin</th>\n",
       "      <th>is_low_K</th>\n",
       "      <th>is_high_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>13.026420</td>\n",
       "      <td>443.816419</td>\n",
       "      <td>440</td>\n",
       "      <td>0.257937</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>Under</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991401</td>\n",
       "      <td>-3.816419</td>\n",
       "      <td>447.216498</td>\n",
       "      <td>...</td>\n",
       "      <td>3.843585</td>\n",
       "      <td>-0.032928</td>\n",
       "      <td>-0.062958</td>\n",
       "      <td>1.911993</td>\n",
       "      <td>436.654786</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>0.125001</td>\n",
       "      <td>448.076828</td>\n",
       "      <td>500</td>\n",
       "      <td>0.313492</td>\n",
       "      <td>0.02972</td>\n",
       "      <td>Over</td>\n",
       "      <td>1</td>\n",
       "      <td>1.115880</td>\n",
       "      <td>51.923172</td>\n",
       "      <td>452.209662</td>\n",
       "      <td>...</td>\n",
       "      <td>3.559516</td>\n",
       "      <td>0.418711</td>\n",
       "      <td>0.388991</td>\n",
       "      <td>0.929020</td>\n",
       "      <td>495.430401</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Value           S    K       tau        r     BS  BS_binary  \\\n",
       "Unnamed: 0                                                                    \n",
       "688         13.026420  443.816419  440  0.257937  0.03003  Under          0   \n",
       "1078         0.125001  448.076828  500  0.313492  0.02972   Over          1   \n",
       "\n",
       "            KS_ratio    KS_diff  risk_free_FV  ...  KS_tau_ratio   r_asset  \\\n",
       "Unnamed: 0                                     ...                           \n",
       "688         0.991401  -3.816419    447.216498  ...      3.843585 -0.032928   \n",
       "1078        1.115880  51.923172    452.209662  ...      3.559516  0.418711   \n",
       "\n",
       "            risk_free_rate_abs  risk_free_rate_prop  S_expected  S_bin  K_bin  \\\n",
       "Unnamed: 0                                                                      \n",
       "688                  -0.062958             1.911993  436.654786      3      3   \n",
       "1078                  0.388991             0.929020  495.430401      5      5   \n",
       "\n",
       "            r_bin  is_low_K  is_high_r  \n",
       "Unnamed: 0                              \n",
       "688             2         0          0  \n",
       "1078            1         0          0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset=pd.read_csv('train.csv',index_col=0)\n",
    "trainset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d33a00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T19:47:55.041597Z",
     "start_time": "2022-05-05T19:47:54.983606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>S</th>\n",
       "      <th>K</th>\n",
       "      <th>tau</th>\n",
       "      <th>r</th>\n",
       "      <th>BS</th>\n",
       "      <th>BS_binary</th>\n",
       "      <th>KS_ratio</th>\n",
       "      <th>KS_diff</th>\n",
       "      <th>risk_free_FV</th>\n",
       "      <th>...</th>\n",
       "      <th>KS_tau_ratio</th>\n",
       "      <th>r_asset</th>\n",
       "      <th>risk_free_rate_abs</th>\n",
       "      <th>risk_free_rate_prop</th>\n",
       "      <th>S_expected</th>\n",
       "      <th>S_bin</th>\n",
       "      <th>K_bin</th>\n",
       "      <th>r_bin</th>\n",
       "      <th>is_low_K</th>\n",
       "      <th>is_high_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>32.175766</td>\n",
       "      <td>429.314292</td>\n",
       "      <td>400</td>\n",
       "      <td>0.150794</td>\n",
       "      <td>0.03085</td>\n",
       "      <td>Under</td>\n",
       "      <td>0</td>\n",
       "      <td>0.931718</td>\n",
       "      <td>-29.314292</td>\n",
       "      <td>431.285782</td>\n",
       "      <td>...</td>\n",
       "      <td>6.178764</td>\n",
       "      <td>-0.374383</td>\n",
       "      <td>-0.405233</td>\n",
       "      <td>1.082402</td>\n",
       "      <td>398.171524</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>0.345000</td>\n",
       "      <td>447.580024</td>\n",
       "      <td>465</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.02982</td>\n",
       "      <td>Over</td>\n",
       "      <td>1</td>\n",
       "      <td>1.038920</td>\n",
       "      <td>17.419976</td>\n",
       "      <td>448.729662</td>\n",
       "      <td>...</td>\n",
       "      <td>11.900361</td>\n",
       "      <td>0.548611</td>\n",
       "      <td>0.518791</td>\n",
       "      <td>0.945645</td>\n",
       "      <td>463.808677</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Value           S    K       tau        r     BS  BS_binary  \\\n",
       "Unnamed: 0                                                                    \n",
       "1274        32.175766  429.314292  400  0.150794  0.03085  Under          0   \n",
       "1527         0.345000  447.580024  465  0.087302  0.02982   Over          1   \n",
       "\n",
       "            KS_ratio    KS_diff  risk_free_FV  ...  KS_tau_ratio   r_asset  \\\n",
       "Unnamed: 0                                     ...                           \n",
       "1274        0.931718 -29.314292    431.285782  ...      6.178764 -0.374383   \n",
       "1527        1.038920  17.419976    448.729662  ...     11.900361  0.548611   \n",
       "\n",
       "            risk_free_rate_abs  risk_free_rate_prop  S_expected  S_bin  K_bin  \\\n",
       "Unnamed: 0                                                                      \n",
       "1274                 -0.405233             1.082402  398.171524      1      1   \n",
       "1527                  0.518791             0.945645  463.808677      4      5   \n",
       "\n",
       "            r_bin  is_low_K  is_high_r  \n",
       "Unnamed: 0                              \n",
       "1274            5         1          0  \n",
       "1527            2         0          0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset=pd.read_csv('test.csv',index_col=0)\n",
    "testset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "845756fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T19:47:58.564701Z",
     "start_time": "2022-05-05T19:47:58.556013Z"
    }
   },
   "outputs": [],
   "source": [
    "basic_var=['r','K','tau','S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff77411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T22:34:45.416973Z",
     "start_time": "2022-04-16T22:34:45.406941Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_rankedvariable = ['KS_ratio',\n",
    " 'risk_free_FV',\n",
    " 'r_bin',\n",
    " 'is_low_K',\n",
    " 'S_bin',\n",
    " 'KS_tau_ratio',\n",
    " 'S_expected',\n",
    " 'r',\n",
    " 'K_bin',\n",
    " 'r_asset',\n",
    " 'risk_free_gap_abs',\n",
    " 'K',\n",
    " 'risk_free_rate_abs',\n",
    " 'is_high_r',\n",
    " 'KS_diff',\n",
    " 'tau',\n",
    " 'S',\n",
    " 'risk_free_rate_prop',\n",
    " 'risk_free_gap_prop']\n",
    "len(class_rankedvariable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc1e6c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T22:36:55.387819Z",
     "start_time": "2022-04-16T22:36:55.356880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_rankedvariable=['risk_free_gap_abs', 'tau', 'risk_free_rate_prop', 'risk_free_FV',\n",
    "                    'K', 'KS_tau_ratio', 'r_asset', 'K_bin', 'is_high_r', 'r_bin', 'r',\n",
    "                    'S', 'is_low_K', 'KS_diff', 'risk_free_gap_prop', 'KS_ratio',\n",
    "                    'S_bin', 'risk_free_rate_abs', 'S_expected']\n",
    "len(reg_rankedvariable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb1afd92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T19:48:14.500221Z",
     "start_time": "2022-05-05T19:48:14.491280Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train_num = pd.DataFrame(trainset.loc[:,'Value'])\n",
    "Y_train_cat = pd.DataFrame(trainset.loc[:,'BS_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9f0bf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T19:48:16.326035Z",
     "start_time": "2022-05-05T19:48:16.301023Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train_num = pd.DataFrame(trainset.loc[:,'Value'])\n",
    "Y_train_cat = pd.DataFrame(trainset.loc[:,'BS_binary'])\n",
    "Y_test_num = pd.DataFrame(testset.loc[:,'Value'])\n",
    "Y_test_cat = pd.DataFrame(testset.loc[:,'BS_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cbc1a9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T22:34:49.318029Z",
     "start_time": "2022-04-16T22:34:49.313124Z"
    }
   },
   "outputs": [],
   "source": [
    "varnum=[3,5,10,15,19]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5596a0e3",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdbf14da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T19:55:59.276748Z",
     "start_time": "2022-05-05T19:55:59.165852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 for Train Value: [0.90101548 0.89770844 0.91766737 0.92286711 0.90376414]\n",
      "mean r2: 0.908604506186391\n",
      "adjusted r2: 0.9082912397123084\n",
      "the best test score: 0.9124915375439029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# basic var\n",
    "kfolds_regression = KFold(n_splits = 5, random_state = 1, shuffle = True) \n",
    "regresssion_model = LinearRegression()\n",
    "\n",
    "var_to_consider=['r','K','tau','S']\n",
    "X_train=trainset[var_to_consider]\n",
    "X_test=testset[var_to_consider]\n",
    "r2_model_1_cv = cross_val_score(regresssion_model, X_train, Y_train_num.values.ravel(), \n",
    "                                    cv=kfolds_regression,scoring='r2')\n",
    "adj_r2=1-(1-np.mean(r2_model_1_cv))*(len(trainset)-1)/(len(trainset)-4-1)\n",
    "best_lm = regresssion_model.fit(X_train, Y_train_num.values.ravel())\n",
    "test_pred = best_lm.predict(X_test)\n",
    "test_score = r2_score(y_true = Y_test_num, y_pred = test_pred)\n",
    "print(f\"r2 for Train Value: {r2_model_1_cv}\\nmean r2: {np.mean(r2_model_1_cv)}\\nadjusted r2: {adj_r2}\")\n",
    "print(f'the best test score: {test_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcf2750d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T22:37:01.549977Z",
     "start_time": "2022-04-16T22:37:01.257951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- variables to consider: 3 --\n",
      "r2 for Train Value: [0.90102576 0.89741859 0.91806814 0.92271792 0.90387966]\n",
      "mean r2: 0.9086220172226456\n",
      "adjusted r2: 0.9083873134997585\n",
      "the best test score: 0.9121968167598762\n",
      "\n",
      "-- variables to consider: 5 --\n",
      "r2 for Train Value: [0.90055498 0.89786329 0.91810496 0.92262489 0.90367175]\n",
      "mean r2: 0.908563975866668\n",
      "adjusted r2: 0.9081718831388236\n",
      "the best test score: 0.9115015945273724\n",
      "\n",
      "-- variables to consider: 10 --\n",
      "r2 for Train Value: [0.89892055 0.89899565 0.92018221 0.92338726 0.90334296]\n",
      "mean r2: 0.908965727293166\n",
      "adjusted r2: 0.9081816250304027\n",
      "the best test score: 0.9144359509687237\n",
      "\n",
      "-- variables to consider: 15 --\n",
      "r2 for Train Value: [0.9802915  0.98706906 0.98896129 0.98605047 0.98594374]\n",
      "mean r2: 0.9856632142091197\n",
      "adjusted r2: 0.9854771832516256\n",
      "the best test score: 0.9850534183420538\n",
      "\n",
      "-- variables to consider: 19 --\n",
      "r2 for Train Value: [0.99215485 0.99289668 0.99398559 0.99253754 0.99299887]\n",
      "mean r2: 0.9929147049346023\n",
      "adjusted r2: 0.9927978467694613\n",
      "the best test score: 0.9931814231201705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfolds_regression = KFold(n_splits = 5, random_state = 1, shuffle = True) \n",
    "regresssion_model = LinearRegression()\n",
    "for i in varnum:\n",
    "    print(f'-- variables to consider: {i} --')\n",
    "    var_to_consider=reg_rankedvariable[:i]\n",
    "    X_train=trainset[var_to_consider]\n",
    "    X_test=testset[var_to_consider]\n",
    "    r2_model_1_cv = cross_val_score(regresssion_model, X_train, Y_train_num.values.ravel(), \n",
    "                                    cv=kfolds_regression,scoring='r2')\n",
    "    adj_r2=1-(1-np.mean(r2_model_1_cv))*(len(trainset)-1)/(len(trainset)-i-1)\n",
    "    best_lm = regresssion_model.fit(X_train, Y_train_num.values.ravel())\n",
    "    test_pred = best_lm.predict(X_test)\n",
    "    test_score = r2_score(y_true = Y_test_num, y_pred = test_pred)\n",
    "    print(f\"r2 for Train Value: {r2_model_1_cv}\\nmean r2: {np.mean(r2_model_1_cv)}\\nadjusted r2: {adj_r2}\")\n",
    "    print(f'the best test score: {test_score}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41260b70",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1dbf68cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T07:47:09.370981Z",
     "start_time": "2022-04-11T07:47:05.779553Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=100, shuffle=True),\n",
       "             estimator=RFE(estimator=LinearRegression()),\n",
       "             param_grid=[{'n_features_to_select': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                   10, 11, 12, 13, 14, 15, 16,\n",
       "                                                   17, 18, 19, 20]}],\n",
       "             return_train_score=True, scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfolds_regression = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'n_features_to_select': list(range(1, 21))}]\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, Y_train_num)\n",
    "rfe = RFE(lm)             \n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = rfe, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'r2', \n",
    "                        cv = kfolds_regression, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, Y_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87d38e9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T07:47:15.392764Z",
     "start_time": "2022-04-11T07:47:15.373013Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_features_to_select</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.527204</td>\n",
       "      <td>0.528763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.878955</td>\n",
       "      <td>0.880505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.879494</td>\n",
       "      <td>0.880628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.910594</td>\n",
       "      <td>0.912097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.910195</td>\n",
       "      <td>0.910582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.910437</td>\n",
       "      <td>0.912260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.910593</td>\n",
       "      <td>0.912591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.912087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.911894</td>\n",
       "      <td>0.913715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.992028</td>\n",
       "      <td>0.992242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.992050</td>\n",
       "      <td>0.992308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.992619</td>\n",
       "      <td>0.992965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.992784</td>\n",
       "      <td>0.993167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.992937</td>\n",
       "      <td>0.993364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.992911</td>\n",
       "      <td>0.993376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.993032</td>\n",
       "      <td>0.993440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.993111</td>\n",
       "      <td>0.993641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.993341</td>\n",
       "      <td>0.993714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.993285</td>\n",
       "      <td>0.993700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.993285</td>\n",
       "      <td>0.993700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_features_to_select  mean_test_score  mean_train_score\n",
       "0                           1         0.527204          0.528763\n",
       "1                           2         0.878955          0.880505\n",
       "2                           3         0.879494          0.880628\n",
       "3                           4         0.910594          0.912097\n",
       "4                           5         0.910195          0.910582\n",
       "5                           6         0.910437          0.912260\n",
       "6                           7         0.910593          0.912591\n",
       "7                           8         0.910782          0.912087\n",
       "8                           9         0.911894          0.913715\n",
       "9                          10         0.992028          0.992242\n",
       "10                         11         0.992050          0.992308\n",
       "11                         12         0.992619          0.992965\n",
       "12                         13         0.992784          0.993167\n",
       "13                         14         0.992937          0.993364\n",
       "14                         15         0.992911          0.993376\n",
       "15                         16         0.993032          0.993440\n",
       "16                         17         0.993111          0.993641\n",
       "17                         18         0.993341          0.993714\n",
       "18                         19         0.993285          0.993700\n",
       "19                         20         0.993285          0.993700"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results.loc[:,['param_n_features_to_select','mean_test_score','mean_train_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "412416d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T07:47:19.437740Z",
     "start_time": "2022-04-11T07:47:19.082068Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f80342b90d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting cv results\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('r-squared')\n",
    "plt.title(\"Optimal Number of Features\")\n",
    "plt.legend(['test score', 'train score'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa162e17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T07:51:12.030515Z",
     "start_time": "2022-04-11T07:51:11.877735Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9931929436640493\n"
     ]
    }
   ],
   "source": [
    "# final model\n",
    "n_features_optimal = 9\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, Y_train_num)\n",
    "\n",
    "rfe = RFE(lm, n_features_to_select=n_features_optimal)             \n",
    "rfe = rfe.fit(X_train, Y_train_num)\n",
    "\n",
    "# predict prices of X_test\n",
    "Y_pred_num = lm.predict(X_test)\n",
    "r2 = sklearn.metrics.r2_score(Y_test_num, Y_pred_num)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44832423",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "023956c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T19:58:19.458512Z",
     "start_time": "2022-05-05T19:58:19.241841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Train BS_binary: [0.90638298 0.92340426 0.91452991 0.93162393 0.9017094 ] \n",
      "mean accuracy: 0.9155300963811603)\n",
      "the best test score: 0.8986083499005965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfolds_regresssion = KFold(n_splits = 5, random_state = 1, shuffle = True) \n",
    "logistic_model = LogisticRegression(penalty='none', max_iter = 10000)\n",
    "var_to_consider=['r','K','tau','S']\n",
    "X_train=trainset[var_to_consider]\n",
    "X_test=testset[var_to_consider]\n",
    "acc_model_2_cv = cross_val_score(logistic_model, X_train, Y_train_cat.values.ravel(), cv=kfolds_regresssion,scoring='accuracy')\n",
    "best_lm = logistic_model.fit(X_train, Y_train_cat.values.ravel())\n",
    "test_pred = best_lm.predict(X_test)\n",
    "test_score = accuracy_score(y_true = Y_test_cat, y_pred = test_pred)\n",
    "print(f\"accuracy for Train BS_binary: {acc_model_2_cv} \\nmean accuracy: {np.mean(acc_model_2_cv)})\")\n",
    "print(f'the best test score: {test_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "346006a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T21:18:48.200811Z",
     "start_time": "2022-04-11T21:18:45.421531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- variables to consider: 3 --\n",
      "accuracy for Train BS_binary: [0.91489362 0.92765957 0.90598291 0.93589744 0.9017094 ] \n",
      "mean accuracy: 0.9172285870158211)\n",
      "the best test score: 0.8906560636182903\n",
      "\n",
      "-- variables to consider: 5 --\n",
      "accuracy for Train BS_binary: [0.91489362 0.91914894 0.90598291 0.91880342 0.88034188] \n",
      "mean accuracy: 0.9078341516639388)\n",
      "the best test score: 0.9085487077534792\n",
      "\n",
      "-- variables to consider: 10 --\n",
      "accuracy for Train BS_binary: [0.91914894 0.92765957 0.91880342 0.93589744 0.9017094 ] \n",
      "mean accuracy: 0.9206437534097109)\n",
      "the best test score: 0.9165009940357853\n",
      "\n",
      "-- variables to consider: 15 --\n",
      "accuracy for Train BS_binary: [0.91914894 0.93191489 0.91880342 0.92735043 0.89316239] \n",
      "mean accuracy: 0.9180760138206947)\n",
      "the best test score: 0.9125248508946322\n",
      "\n",
      "-- variables to consider: 19 --\n",
      "accuracy for Train BS_binary: [0.91914894 0.92765957 0.91452991 0.92307692 0.8974359 ] \n",
      "mean accuracy: 0.9163702491362067)\n",
      "the best test score: 0.9125248508946322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfolds_regresssion = KFold(n_splits = 5, random_state = 1, shuffle = True) \n",
    "logistic_model = LogisticRegression(penalty='none', max_iter = 10000)\n",
    "for i in varnum:\n",
    "    print(f'-- variables to consider: {i} --')\n",
    "    var_to_consider=class_rankedvariable[:i]\n",
    "    X_train=trainset[var_to_consider]\n",
    "    X_test=testset[var_to_consider]\n",
    "    acc_model_2_cv = cross_val_score(logistic_model, X_train, Y_train_cat.values.ravel(), cv=kfolds_regresssion,scoring='accuracy')\n",
    "    best_lm = logistic_model.fit(X_train, Y_train_cat.values.ravel())\n",
    "    test_pred = best_lm.predict(X_test)\n",
    "    test_score = accuracy_score(y_true = Y_test_cat, y_pred = test_pred)\n",
    "    print(f\"accuracy for Train BS_binary: {acc_model_2_cv} \\nmean accuracy: {np.mean(acc_model_2_cv)})\")\n",
    "    print(f'the best test score: {test_score}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6b40f0",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cb34c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T21:42:24.496547Z",
     "start_time": "2022-04-11T21:19:26.494375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- variables to consider: 3 --\n",
      "the best set of parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "the best train score: 0.9292016730314602\n",
      "the best test score: 0.9204771371769384\n",
      "\n",
      "-- variables to consider: 5 --\n",
      "the best set of parameters: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "the best train score: 0.9283396981269323\n",
      "the best test score: 0.9264413518886679\n",
      "\n",
      "-- variables to consider: 10 --\n",
      "the best set of parameters: {'max_depth': 25, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "the best train score: 0.9274959083469723\n",
      "the best test score: 0.9324055666003976\n",
      "\n",
      "-- variables to consider: 15 --\n",
      "the best set of parameters: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 60}\n",
      "the best train score: 0.9274849972722313\n",
      "the best test score: 0.9324055666003976\n",
      "\n",
      "-- variables to consider: 19 --\n",
      "the best set of parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "the best train score: 0.9257755955628296\n",
      "the best test score: 0.9324055666003976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy, BS_binary\n",
    "for i in varnum:   \n",
    "    print(f'-- variables to consider: {i} --')\n",
    "    var_to_consider=class_rankedvariable[:i]\n",
    "    X_train=trainset[var_to_consider]\n",
    "    X_test=testset[var_to_consider]\n",
    "    rfc = RandomForestClassifier()\n",
    "    forest_params = [{'n_estimators':list(range(10, 100,10)),'max_depth': list(range(5, 30,5)),\n",
    "                     'min_samples_split':[2,5,10],'min_samples_leaf':[1,2,4]}]\n",
    "    clf = GridSearchCV(rfc, forest_params, cv = 5, scoring='accuracy')\n",
    "    grid_result_rfc=clf.fit(X_train, Y_train_cat.values.ravel())\n",
    "    best_params_rfc = grid_result_rfc.best_params_\n",
    "    best_score = grid_result_rfc.best_score_\n",
    "    \n",
    "    best_rfc = RandomForestClassifier(n_estimators=best_params_rfc['n_estimators'],\n",
    "                                     max_depth=best_params_rfc['max_depth'],\n",
    "                                     min_samples_split=best_params_rfc['min_samples_split'],\n",
    "                                     min_samples_leaf=best_params_rfc['min_samples_leaf'])\n",
    "    best_rfc.fit(X_train, Y_train_cat.values.ravel())\n",
    "    test_pred = best_rfc.predict(X_test)\n",
    "    test_score = accuracy_score(y_true = Y_test_cat, y_pred = test_pred)\n",
    "    print(f'the best set of parameters: {best_params_rfc}') \n",
    "    print(f'the best train score: {best_score}') \n",
    "    print(f'the best test score: {test_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd8c8078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T23:45:49.098114Z",
     "start_time": "2022-04-16T22:38:43.305930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- variables to consider: 3 --\n",
      "the best set of parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 90}\n",
      "the best train score: 0.9984112369020008\n",
      "the best test score: 0.9988727353093056\n",
      "\n",
      "-- variables to consider: 5 --\n",
      "the best set of parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 80}\n",
      "the best train score: 0.9983670872228998\n",
      "the best test score: 0.9988822654792106\n",
      "\n",
      "-- variables to consider: 10 --\n",
      "the best set of parameters: {'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 90}\n",
      "the best train score: 0.9983853502543638\n",
      "the best test score: 0.9989072567038196\n",
      "\n",
      "-- variables to consider: 15 --\n",
      "the best set of parameters: {'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 70}\n",
      "the best train score: 0.9982747638036912\n",
      "the best test score: 0.9987324229137176\n",
      "\n",
      "-- variables to consider: 19 --\n",
      "the best set of parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 30}\n",
      "the best train score: 0.9982115946097988\n",
      "the best test score: 0.9985584535281152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# r2, Value\n",
    "for i in varnum:   \n",
    "    print(f'-- variables to consider: {i} --')\n",
    "    var_to_consider=reg_rankedvariable[:i]\n",
    "    X_train=trainset[var_to_consider]\n",
    "    X_test=testset[var_to_consider]\n",
    "    rfr = RandomForestRegressor()\n",
    "    forest_params = [{'n_estimators':list(range(10, 100,10)),'max_depth': list(range(5, 31,5)),\n",
    "                     'min_samples_split':[2,5,10],'min_samples_leaf':[1,2,4]}]\n",
    "    clf = GridSearchCV(rfr, forest_params, cv = 5, scoring='r2')\n",
    "    grid_result_rfr=clf.fit(X_train, Y_train_num.values.ravel())\n",
    "    best_params_rfr = grid_result_rfr.best_params_\n",
    "    best_score = grid_result_rfr.best_score_\n",
    "    \n",
    "    best_rfr = RandomForestRegressor(n_estimators=best_params_rfr['n_estimators'],\n",
    "                                     max_depth=best_params_rfr['max_depth'],\n",
    "                                     min_samples_split=best_params_rfr['min_samples_split'],\n",
    "                                     min_samples_leaf=best_params_rfr['min_samples_leaf'])\n",
    "    best_rfr.fit(X_train, Y_train_num.values.ravel())\n",
    "    test_pred = best_rfr.predict(X_test)\n",
    "    test_score = r2_score(y_true = Y_test_num, y_pred = test_pred)\n",
    "    print(f'the best set of parameters: {best_params_rfr}') \n",
    "    print(f'the best train score: {best_score}') \n",
    "    print(f'the best test score: {test_score}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dd4ac3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1beda9c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-16T22:37:43.374626Z",
     "start_time": "2022-04-16T22:37:12.044003Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- variables to consider: 3 --\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m forest_params \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m10\u001b[39m)),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m5\u001b[39m))}]\n\u001b[1;32m      9\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(rfr, forest_params, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m grid_result_rfr\u001b[38;5;241m=\u001b[39m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_num\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m best_params_rfr \u001b[38;5;241m=\u001b[39m grid_result_rfr\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[1;32m     12\u001b[0m best_score \u001b[38;5;241m=\u001b[39m grid_result_rfr\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:702\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    699\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    701\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m--> 702\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:761\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    759\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test)\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 761\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_score \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py:216\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, estimator, X, y_true, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m        Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cached_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py:258\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_score\u001b[39m(\u001b[38;5;28mself\u001b[39m, method_caller, estimator, X, y_true, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m        Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(\n\u001b[1;32m    261\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs\n\u001b[1;32m    262\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_scorer.py:68\u001b[0m, in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[method]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:984\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;66;03m# Parallel loop\u001b[39;00m\n\u001b[1;32m    983\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[0;32m--> 984\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m y_hat \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_hat\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# r2, Value\n",
    "for i in varnum:   \n",
    "    print(f'-- variables to consider: {i} --')\n",
    "    var_to_consider=reg_rankedvariable[:i]\n",
    "    X_train=trainset[var_to_consider]\n",
    "    X_test=testset[var_to_consider]\n",
    "    rfr = RandomForestRegressor()\n",
    "    forest_params = [{'n_estimators':list(range(10, 100,10)),'max_depth': list(range(5, 30,5))}]\n",
    "    clf = GridSearchCV(rfr, forest_params, cv = 5, scoring='r2')\n",
    "    grid_result_rfr=clf.fit(X_train, Y_train_num.values.ravel())\n",
    "    best_params_rfr = grid_result_rfr.best_params_\n",
    "    best_score = grid_result_rfr.best_score_\n",
    "    \n",
    "    best_rfr = RandomForestRegressor(n_estimators=best_params_rfr['n_estimators'],\n",
    "                                     max_depth=best_params_rfr['max_depth'])\n",
    "    best_rfr.fit(X_train, Y_train_num.values.ravel())\n",
    "    test_pred = best_rfr.predict(X_test)\n",
    "    test_score = r2_score(y_true = Y_test_num, y_pred = test_pred)\n",
    "    print(f'the best set of parameters: {best_params_rfr}') \n",
    "    print(f'the best train score: {best_score}') \n",
    "    print(f'the best test score: {test_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e4c86e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T18:24:40.469803Z",
     "start_time": "2022-04-11T18:22:14.090934Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- variables to consider: 3 --\n",
      "{'max_depth': 20, 'n_estimators': 90}\n",
      "0.6459557985873776\n",
      "-- variables to consider: 5 --\n",
      "{'max_depth': 10, 'n_estimators': 50}\n",
      "0.6494317344162546\n",
      "-- variables to consider: 10 --\n",
      "{'max_depth': 5, 'n_estimators': 10}\n",
      "0.6633468698484178\n",
      "-- variables to consider: 15 --\n",
      "{'max_depth': 5, 'n_estimators': 60}\n",
      "0.6772050446973049\n",
      "-- variables to consider: 20 --\n",
      "{'max_depth': 20, 'n_estimators': 90}\n",
      "0.6737518931017383\n"
     ]
    }
   ],
   "source": [
    "# r2, BS_binary\n",
    "for i in varnum:   \n",
    "    print(f'-- variables to consider: {i} --')\n",
    "    var_to_consider=rankedvariable[:i]\n",
    "    X_train=trainset[var_to_consider]\n",
    "    X_test=testset[var_to_consider]\n",
    "    rfc = RandomForestClassifier()\n",
    "    forest_params = [{'n_estimators':list(range(10, 100,10)),'max_depth': list(range(5, 30,5))}]\n",
    "    clf = GridSearchCV(rfc, forest_params, cv = 5, scoring='r2')\n",
    "    clf.fit(X_train, Y_train_cat.values.ravel())\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16a8d2dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T23:21:22.030004Z",
     "start_time": "2022-04-07T23:21:18.194729Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=100, shuffle=True),\n",
       "             estimator=RFE(estimator=LinearRegression()),\n",
       "             param_grid=[{'n_features_to_select': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                   10, 11, 12, 13, 14, 15, 16,\n",
       "                                                   17, 18, 19, 20]}],\n",
       "             return_train_score=True, scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfolds_regression = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'n_features_to_select': list(range(1, 21))}]\n",
    "\n",
    "\n",
    "# step-3: perform grid search\n",
    "# 3.1 specify model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, Y_train_cat)\n",
    "rfe = RFE(lm)             \n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = rfe, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'r2', \n",
    "                        cv = kfolds_regression, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, Y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bc15247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T23:32:59.553590Z",
     "start_time": "2022-04-07T23:32:59.530527Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_features_to_select</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.250445</td>\n",
       "      <td>0.255273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.627130</td>\n",
       "      <td>0.628912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.626570</td>\n",
       "      <td>0.628794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.625781</td>\n",
       "      <td>0.629507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.625433</td>\n",
       "      <td>0.629611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.627351</td>\n",
       "      <td>0.631693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.628878</td>\n",
       "      <td>0.632912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.628794</td>\n",
       "      <td>0.633282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.632132</td>\n",
       "      <td>0.635605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.631467</td>\n",
       "      <td>0.636773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.632510</td>\n",
       "      <td>0.637488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.635269</td>\n",
       "      <td>0.643512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>0.649716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.646862</td>\n",
       "      <td>0.653406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.646740</td>\n",
       "      <td>0.653728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.646190</td>\n",
       "      <td>0.653601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.645024</td>\n",
       "      <td>0.654859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.638058</td>\n",
       "      <td>0.657594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.642754</td>\n",
       "      <td>0.659147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.642754</td>\n",
       "      <td>0.659147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_features_to_select  mean_test_score  mean_train_score\n",
       "0                           1         0.250445          0.255273\n",
       "1                           2         0.627130          0.628912\n",
       "2                           3         0.626570          0.628794\n",
       "3                           4         0.625781          0.629507\n",
       "4                           5         0.625433          0.629611\n",
       "5                           6         0.627351          0.631693\n",
       "6                           7         0.628878          0.632912\n",
       "7                           8         0.628794          0.633282\n",
       "8                           9         0.632132          0.635605\n",
       "9                          10         0.631467          0.636773\n",
       "10                         11         0.632510          0.637488\n",
       "11                         12         0.635269          0.643512\n",
       "12                         13         0.640365          0.649716\n",
       "13                         14         0.646862          0.653406\n",
       "14                         15         0.646740          0.653728\n",
       "15                         16         0.646190          0.653601\n",
       "16                         17         0.645024          0.654859\n",
       "17                         18         0.638058          0.657594\n",
       "18                         19         0.642754          0.659147\n",
       "19                         20         0.642754          0.659147"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results.loc[:,['param_n_features_to_select','mean_test_score','mean_train_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f742f0cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T23:23:31.527925Z",
     "start_time": "2022-04-07T23:23:30.516223Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff1b9602850>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting cv results\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('r-squared')\n",
    "plt.title(\"Optimal Number of Features\")\n",
    "plt.legend(['test score', 'train score'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e59a620e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T23:41:43.361522Z",
     "start_time": "2022-04-07T23:41:43.314882Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# final model\n",
    "n_features_optimal = 14\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, Y_train_cat)\n",
    "\n",
    "rfe = RFE(lm, n_features_to_select=n_features_optimal)             \n",
    "rfe = rfe.fit(X_train, Y_train_cat)\n",
    "\n",
    "# predict prices of X_test\n",
    "Y_pred_cat = lm.predict(X_test)\n",
    "# r2 = sklearn.metrics.r2_score(y_test, Y_pred_cat)\n",
    "# print(r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
